{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Recommendation Engines Homework\n\nWorking through different types of recommendation systems for this assignment."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# importing what I need\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.decomposition import NMF\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# setting up plots\nplt.style.use(\"seaborn-v0_8\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 1: Setting up the data"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# creating fake data since we dont have real data\nnp.random.seed(42)\n\n# making a matrix with 100 users and 50 items\nn_users = 100\nn_items = 50\n# ratings from 0-5, with lots of 0s (sparse data)\nratings = np.random.choice([0, 1, 2, 3, 4, 5], size=(n_users, n_items), p=[0.6, 0.1, 0.1, 0.1, 0.05, 0.05])\n\nusers = [f\"User_{i}\" for i in range(n_users)]\nitems = [f\"Item_{i}\" for i in range(n_items)]\n\ndf = pd.DataFrame(ratings, index=users, columns=items)\nprint(\"Matrix shape:\", df.shape)\nprint(df.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# checking the data\nprint(f\"Total ratings: {df.values.sum()}\")\nprint(f\"Average rating: {df.values.mean():.2f}\")\nprint(f\"How sparse: {(df == 0).sum().sum() / (n_users * n_items) * 100:.1f}%\")\n\n# plot distribution\nrating_dist = pd.Series(ratings.flatten()).value_counts().sort_index()\nplt.figure(figsize=(8, 5))\nrating_dist.plot(kind=\"bar\")\nplt.title(\"Rating Distribution\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 2: User-based collaborative filtering\n\nTrying to find similar users and recommend based on what they liked."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def user_cf(user_id, num_recs=5):\n    # get this users ratings\n    user_ratings = df.loc[user_id]\n    \n    # find similar users\n    similarities = cosine_similarity([user_ratings], df)[0]\n    similar_users = pd.Series(similarities, index=users).sort_values(ascending=False)[1:6]  # top 5\n    \n    # find items this user hasnt rated\n    unrated = user_ratings[user_ratings == 0].index\n    \n    # predict ratings\n    predictions = {}\n    for item in unrated:\n        item_ratings = df.loc[similar_users.index, item]\n        rated_by_similar = item_ratings[item_ratings > 0]\n        if len(rated_by_similar) > 0:\n            weights = similar_users.loc[rated_by_similar.index]\n            pred = np.average(rated_by_similar, weights=weights)\n            predictions[item] = pred\n    \n    # get top recommendations\n    recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n    return recs[:num_recs]\n\n# test it\ntest_user = \"User_0\"\nrecs = user_cf(test_user)\nprint(f\"Recommendations for {test_user}:\")\nfor item, score in recs:\n    print(f\"{item}: {score:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 3: Item-based collaborative filtering\n\nNow trying item similarities instead of user similarities."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def item_cf(user_id, num_recs=5):\n    user_ratings = df.loc[user_id]\n    \n    # calculate item similarities\n    item_sim = cosine_similarity(df.T)\n    item_sim_df = pd.DataFrame(item_sim, index=items, columns=items)\n    \n    unrated = user_ratings[user_ratings == 0].index\n    \n    predictions = {}\n    for item in unrated:\n        rated_items = user_ratings[user_ratings > 0].index\n        if len(rated_items) > 0:\n            sims = item_sim_df.loc[item, rated_items]\n            ratings = user_ratings[rated_items]\n            # only use positive similarities\n            pos_sims = sims > 0\n            if pos_sims.sum() > 0:\n                pred = np.average(ratings[pos_sims], weights=sims[pos_sims])\n                predictions[item] = pred\n    \n    recs = sorted(predictions.items(), key=lambda x: x[1], reverse=True)\n    return recs[:num_recs]\n\n# test item-based\nitem_recs = item_cf(test_user)\nprint(f\"Item-based recommendations for {test_user}:\")\nfor item, score in item_recs:\n    print(f\"{item}: {score:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 4: Matrix Factorization with NMF\n\nTrying matrix factorization to find latent factors."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# prep data for NMF - replace 0s with item averages\ndf_nmf = df.copy()\ndf_nmf = df_nmf.replace(0, np.nan)\nitem_means = df_nmf.mean()\ndf_nmf = df_nmf.fillna(item_means)\n\n# run NMF\nnmf = NMF(n_components=10, random_state=42)\nW = nmf.fit_transform(df_nmf)  # user factors\nH = nmf.components_  # item factors\n\n# reconstruct\nreconstructed = np.dot(W, H)\n\nprint(f\"Original shape: {df.shape}\")\nprint(f\"User factors: {W.shape}\")\nprint(f\"Item factors: {H.shape}\")\nprint(f\"Reconstruction error: {nmf.reconstruction_err_:.3f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def nmf_recs(user_id, num_recs=5):\n    user_idx = users.index(user_id)\n    user_preds = reconstructed[user_idx]\n    \n    # only recommend unrated items\n    original = df.loc[user_id]\n    unrated_mask = original == 0\n    \n    unrated_preds = user_preds[unrated_mask]\n    unrated_items = original[unrated_mask].index\n    \n    recs = list(zip(unrated_items, unrated_preds))\n    recs.sort(key=lambda x: x[1], reverse=True)\n    return recs[:num_recs]\n\n# test NMF\nnmf_recommendations = nmf_recs(test_user)\nprint(f\"NMF recommendations for {test_user}:\")\nfor item, score in nmf_recommendations:\n    print(f\"{item}: {score:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 5: Content-based filtering\n\nMaking up some item features to try content-based recommendations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# creating fake item features\nnp.random.seed(42)\ncategories = [\"Electronics\", \"Books\", \"Clothing\", \"Home\", \"Sports\"]\n\nitem_features = {}\nfor item in items:\n    item_features[item] = {\n        \"category\": np.random.choice(categories),\n        \"price\": np.random.choice([\"Low\", \"Medium\", \"High\"]),\n        \"rating\": np.random.uniform(3.0, 5.0)\n    }\n\nfeatures_df = pd.DataFrame.from_dict(item_features, orient=\"index\")\nprint(\"Item features:\")\nprint(features_df.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def content_recs(user_id, num_recs=5):\n    user_ratings = df.loc[user_id]\n    rated_items = user_ratings[user_ratings > 0]\n    \n    if len(rated_items) == 0:\n        # if no ratings, just recommend popular items\n        popular = features_df.sort_values(\"rating\", ascending=False).index\n        return [(item, features_df.loc[item, \"rating\"]) for item in popular[:num_recs]]\n    \n    # build user profile from rated items\n    rated_features = features_df.loc[rated_items.index]\n    fav_category = rated_features[\"category\"].value_counts().index[0]\n    fav_price = rated_features[\"price\"].value_counts().index[0]\n    \n    # score unrated items\n    unrated = user_ratings[user_ratings == 0].index\n    scores = {}\n    \n    for item in unrated:\n        score = 0\n        item_feat = features_df.loc[item]\n        \n        if item_feat[\"category\"] == fav_category:\n            score += 2\n        if item_feat[\"price\"] == fav_price:\n            score += 1\n        score += item_feat[\"rating\"]  # add base rating\n        \n        scores[item] = score\n    \n    recs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n    return recs[:num_recs]\n\n# test content-based\ncontent_recommendations = content_recs(test_user)\nprint(f\"Content-based recommendations for {test_user}:\")\nfor item, score in content_recommendations:\n    print(f\"{item}: {score:.1f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Comparing the methods\n\nQuick comparison of coverage for different approaches."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# test on a few users to see coverage\ntest_users = users[:10]\nmethods = [(\"User CF\", user_cf), (\"Item CF\", item_cf), (\"NMF\", nmf_recs), (\"Content\", content_recs)]\n\nresults = {}\nfor name, func in methods:\n    all_recs = []\n    for user in test_users:\n        try:\n            recs = func(user)\n            all_recs.extend([item for item, score in recs])\n        except:\n            pass\n    \n    unique_items = len(set(all_recs))\n    coverage = unique_items / len(items) * 100\n    results[name] = coverage\n    print(f\"{name}: {unique_items} unique items, {coverage:.1f}% coverage\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nTried different recommendation approaches:\n- User-based collaborative filtering\n- Item-based collaborative filtering  \n- Matrix factorization with NMF\n- Content-based filtering\n\nEach has different strengths. Collaborative filtering works well with enough data, content-based helps with cold start, and matrix factorization can find latent patterns."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}