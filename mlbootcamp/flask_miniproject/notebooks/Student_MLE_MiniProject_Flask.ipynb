{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Student MLE MiniProject: Flask Microservice with ML Model\n",
        "\n",
        "This notebook completes the Springboard MEC2 Flask mini-project by:\n",
        "\n",
        "- Training a simple scikit-learn model and persisting it\n",
        "- Building a Flask microservice exposing `/health` and `/predict`\n",
        "- Providing tests via Flask's test client\n",
        "- Exporting a runnable `app.py`, `requirements.txt`, and `README.md`\n",
        "\n",
        "Reference: [`Student_MLE_MiniProject_Flask.ipynb`](https://github.com/springboard-curriculum/mec2-projects/blob/main/Student_MLE_MiniProject_Flask.ipynb)\n",
        "\n",
        "You can run the app directly without running the notebook; the exported `app.py` will train a model at first startup if a saved model is not found.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Ensure Flask is available in this notebook kernel\n",
        "%pip install -q flask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to Study/mlbootcamp/flask_miniproject/service/artifacts/model.joblib\n",
            "Saved metrics to Study/mlbootcamp/flask_miniproject/service/artifacts/metrics.json\n",
            "Accuracy: 0.9333\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/data_science_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import joblib\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "ARTIFACT_DIR = Path('Study/mlbootcamp/flask_miniproject/service/artifacts')\n",
        "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "MODEL_PATH = ARTIFACT_DIR / 'model.joblib'\n",
        "METRICS_PATH = ARTIFACT_DIR / 'metrics.json'\n",
        "META_PATH = ARTIFACT_DIR / 'meta.json'\n",
        "\n",
        "# Train a simple model (Iris dataset)\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('clf', LogisticRegression(max_iter=1000, multi_class='auto')),\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "pipeline.fit(X_train, y_train)\n",
        "train_time_s = time.time() - start\n",
        "\n",
        "# Evaluate\n",
        "preds = pipeline.predict(X_test)\n",
        "acc = accuracy_score(y_test, preds)\n",
        "report = classification_report(y_test, preds, output_dict=True)\n",
        "\n",
        "metrics: Dict[str, Any] = {\n",
        "    'accuracy': acc,\n",
        "    'classification_report': report,\n",
        "    'train_time_s': train_time_s,\n",
        "    'n_train': int(len(X_train)),\n",
        "    'n_test': int(len(X_test)),\n",
        "}\n",
        "\n",
        "# Persist artifacts\n",
        "joblib.dump(pipeline, MODEL_PATH)\n",
        "with open(METRICS_PATH, 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "with open(META_PATH, 'w') as f:\n",
        "    json.dump({'created_at': time.strftime('%Y-%m-%d %H:%M:%S')}, f)\n",
        "\n",
        "print('Saved model to', MODEL_PATH)\n",
        "print('Saved metrics to', METRICS_PATH)\n",
        "print('Accuracy:', round(acc, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:8000\n",
            " * Running on http://10.99.97.18:8000\n",
            "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [01/Sep/2025 06:31:16] \"\u001b[33mGET /ui HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2025 06:31:16] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2025 06:31:19] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2025 06:31:25] \"\u001b[33mGET /index HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [01/Sep/2025 06:32:28] \"\u001b[33mGET / HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "from flask import Flask, jsonify, request\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "ARTIFACT_DIR = Path('Study/mlbootcamp/flask_miniproject/service/artifacts')\n",
        "MODEL_PATH = ARTIFACT_DIR / 'model.joblib'\n",
        "METRICS_PATH = ARTIFACT_DIR / 'metrics.json'\n",
        "\n",
        "IRIS = load_iris()\n",
        "TARGET_NAMES = list(IRIS.target_names)\n",
        "\n",
        "\n",
        "def ensure_model() -> Pipeline:\n",
        "    ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    if MODEL_PATH.exists():\n",
        "        return joblib.load(MODEL_PATH)\n",
        "    # Train quickly if not present\n",
        "    X, y = IRIS.data, IRIS.target\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', LogisticRegression(max_iter=1000)),\n",
        "    ])\n",
        "    pipeline.fit(X, y)\n",
        "    joblib.dump(pipeline, MODEL_PATH)\n",
        "    return pipeline\n",
        "\n",
        "\n",
        "def create_app() -> Flask:\n",
        "    app = Flask(__name__)\n",
        "    model: Pipeline = ensure_model()\n",
        "\n",
        "    @app.get('/health')\n",
        "    def health() -> Any:\n",
        "        healthy = MODEL_PATH.exists()\n",
        "        metrics: Dict[str, Any] = {}\n",
        "        if METRICS_PATH.exists():\n",
        "            try:\n",
        "                metrics = json.loads(METRICS_PATH.read_text())\n",
        "            except Exception:\n",
        "                metrics = {}\n",
        "        return jsonify({\n",
        "            'status': 'ok' if healthy else 'degraded',\n",
        "            'model_present': healthy,\n",
        "            'metrics': metrics,\n",
        "        })\n",
        "\n",
        "    @app.post('/predict')\n",
        "    def predict() -> Any:\n",
        "        payload = request.get_json(silent=True) or {}\n",
        "        if 'features' not in payload:\n",
        "            return jsonify({'error': 'Missing \"features\" field'}), 400\n",
        "        features = payload['features']\n",
        "        if not isinstance(features, list) or len(features) == 0:\n",
        "            return jsonify({'error': '\"features\" must be a non-empty list'}), 400\n",
        "        try:\n",
        "            X = np.array(features, dtype=float)\n",
        "        except Exception:\n",
        "            return jsonify({'error': 'Could not parse features as numeric'}), 400\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "        if X.shape[1] != IRIS.data.shape[1]:\n",
        "            return jsonify({'error': f'Each sample must have {IRIS.data.shape[1]} features'}), 400\n",
        "        preds = model.predict(X)\n",
        "        proba = None\n",
        "        try:\n",
        "            proba = model.predict_proba(X)\n",
        "        except Exception:\n",
        "            proba = None\n",
        "        classes = [TARGET_NAMES[int(i)] for i in preds]\n",
        "        response: Dict[str, Any] = {\n",
        "            'predictions': preds.tolist(),\n",
        "            'classes': classes,\n",
        "        }\n",
        "        if proba is not None:\n",
        "            response['probabilities'] = np.max(proba, axis=1).tolist()\n",
        "        return jsonify(response)\n",
        "\n",
        "    return app\n",
        "\n",
        "app = create_app()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=int(os.getenv('PORT', '8000')), debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic tests using Flask test client\n",
        "from flask.testing import FlaskClient\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Reuse `app` from previous cell\n",
        "client: FlaskClient = app.test_client()\n",
        "\n",
        "# Test /health\n",
        "resp = client.get('/health')\n",
        "assert resp.status_code == 200, resp.data\n",
        "health_payload = resp.get_json()\n",
        "print('/health:', health_payload)\n",
        "\n",
        "# Test /predict with one sample\n",
        "sample = [5.1, 3.5, 1.4, 0.2]\n",
        "resp = client.post('/predict', json={'features': sample})\n",
        "assert resp.status_code == 200, resp.data\n",
        "pred_payload = resp.get_json()\n",
        "print('/predict one:', pred_payload)\n",
        "\n",
        "# Test /predict with batch\n",
        "batch = [\n",
        "    [5.9, 3.0, 5.1, 1.8],\n",
        "    [6.7, 3.1, 4.7, 1.5],\n",
        "]\n",
        "resp = client.post('/predict', json={'features': batch})\n",
        "assert resp.status_code == 200, resp.data\n",
        "pred_payload = resp.get_json()\n",
        "print('/predict batch:', pred_payload)\n",
        "\n",
        "# Negative cases\n",
        "resp = client.post('/predict', json={})\n",
        "assert resp.status_code == 400\n",
        "resp = client.post('/predict', json={'features': []})\n",
        "assert resp.status_code == 400\n",
        "resp = client.post('/predict', json={'features': [0, 1]})\n",
        "assert resp.status_code == 400\n",
        "\n",
        "print('All tests passed.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "data_science_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
